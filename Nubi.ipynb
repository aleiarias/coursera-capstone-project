{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleiarias/coursera-capstone-project/blob/main/Nubi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "zMKfd_a_LZOY"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meKdhNYLMCzj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import sum, rank\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "\n",
        "# Nueva sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"Nubi_Challenge\").config(\"spark.sql.parquet.enableVectorizedReader\", \"false\").getOrCreate()\n",
        "\n",
        "# Ruta raiz de los archivos parquet\n",
        "root_path = \"compressedData\"\n",
        "\n",
        "# Ruta de los archivos diarios para el periodo analizado\n",
        "day_path = f\"{root_path}/year=2024/month=07/\"\n",
        "\n",
        "# Punto 1: Logging de los dias faltantes considerando los primeros 7\n",
        "for dia in range(1,7):\n",
        "    file_path = os.path.join(day_path, f\"day=2024070{dia}\")\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        # Si el archivo no existe, muestro mensaje en pantalla\n",
        "        print(f\"Error: El dia '2024070{dia}' no existe en la ruta '{day_path}'.\")\n",
        "\n",
        "#Lectura de los archivos parquet\n",
        "try:\n",
        "  df = spark.read.parquet(root_path,header=True)\n",
        "  df.show()\n",
        "  # Punto 2: Calculo de totales\n",
        "\n",
        "  total = df.groupBy(\"sellerId\").agg(sum(\"sales\").alias(\"Total_SI\"),sum(\"price\").alias(\"Total_GMV\"))\n",
        "  total.show()\n",
        "\n",
        "  # Punto 3: Ranking de vendendores\n",
        "\n",
        "  #Defino ventana de partición y ordenación\n",
        "  SI_spec = Window.orderBy(total[\"total_SI\"].desc())\n",
        "  GMV_spec = Window.orderBy(total[\"total_GMV\"].desc())\n",
        "\n",
        "  # Agrego la columna de ranking al dataFrame\n",
        "  df_ranking = total.withColumn(\"rankSI\", rank().over(SI_spec))\n",
        "  df_ranking = df_ranking.withColumn(\"rankGMV\", rank().over(GMV_spec))\n",
        "  df_ranking.show()\n",
        "\n",
        "  # Punto 4: Almaceno el dataframe en un archivo csv\n",
        "  df_ranking.write.mode(\"overwrite\").csv(\"desafionubi.csv\", header=True)\n",
        "  # Mostrar los resultados ordenados por ranking\n",
        "  df_ranking.show()\n",
        "\n",
        "  # Punto 5: Preparo y almaceno el dataframe en un archivo parquet particionado por sellerId\n",
        "  df_aggregated = df.groupBy(\"id\",\"day\",\"sellerId\").agg(sum(\"sales\").alias(\"total_ventas\"))\n",
        "  df_aggregated.show()\n",
        "  df_aggregated.write.mode(\"overwrite\").partitionBy(\"sellerId\").parquet(\"desafio_nubi.parquet\")\n",
        "\n",
        "  # Detener la sesión de Spark\n",
        "  spark.stop()\n",
        "except AnalysisException as e:\n",
        "  # Log de un mensaje si el archivo parquet no existe o no puede ser leído\n",
        "  if \"Ruta no existe\" in str(e):\n",
        "      print(f\"Error: El archivo parquet en la ruta '{file_path}' no existe.\")\n",
        "  else:\n",
        "      print(f\"Error al intentar leer el archivo Parquet: {str(e)}\")\n",
        "\n",
        "except Exception as e:\n",
        "      print(f\"Error al leer los archivos Parquet particionados\")\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfrIdS0tJmz0/rCFRBXujF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}